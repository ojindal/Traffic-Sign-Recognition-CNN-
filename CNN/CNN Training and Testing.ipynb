{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80395f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "\n",
    "data_dir = 'GTSRB/Training'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a80c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All about the classification model and training\n",
    "'''\n",
    "\n",
    "# Define the transformations.\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize([32, 32]),\n",
    "    transforms.RandomPerspective(distortion_scale=0.6, p=0.4),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define path of training data\n",
    "\n",
    "train_data_path = data_dir\n",
    "train_data = datasets.ImageFolder(root = train_data_path, transform = data_transforms)\n",
    "\n",
    "# Divide data into training and validation (0.8 and 0.2)\n",
    "ratio = 0.8\n",
    "n_train_examples = int(len(train_data) * ratio)\n",
    "n_val_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])\n",
    "\n",
    "# Defining the CNN model\n",
    "\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,5,1)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight) # Weight initialization\n",
    "        self.conv2 = nn.Conv2d(32,32,3,1)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.conv3 = nn.Conv2d(32,64,1,1)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        self.conv4 = nn.Conv2d(64,64,3,1)\n",
    "        nn.init.kaiming_normal_(self.conv4.weight)\n",
    "        \n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2_bn = nn.BatchNorm1d(43)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.fc2 = nn.Linear(128, 43)\n",
    "        \n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv2_bn(self.conv2(F.relu(self.conv1_bn(self.conv1(x))))))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv4_bn(self.conv4(F.relu(self.conv3_bn(self.conv3(x))))))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "def check_accuracy(model, dataloader, model_forward='loss'):\n",
    "    y_pred = []\n",
    "    y = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if model_forward!='loss':\n",
    "        model.eval()\n",
    "    for batch, (inputs, labels) in tqdm(enumerate(dataloader, 0)):\n",
    "        inputs = inputs.to(device)\n",
    "        if model_forward=='loss':\n",
    "            scores = model.loss(inputs)\n",
    "        elif model_forward=='forward':\n",
    "            with torch.no_grad():\n",
    "                scores = model(torch.tensor(inputs)).detach()\n",
    "        scores=scores.cpu()\n",
    "        scores=scores.numpy()\n",
    "        y.append(labels)\n",
    "        y_pred.append(np.argmax(scores, axis=1))\n",
    "        \n",
    "    y_pred = np.hstack(y_pred)\n",
    "    y = np.hstack(y)\n",
    "    acc = np.mean(y_pred == y)\n",
    "\n",
    "    return acc*100\n",
    "\n",
    "# Returns the training model\n",
    "def training(epochs, batch_size, results, lr=0.001):\n",
    "    classes=43\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader = data.DataLoader(train_data, shuffle=True, batch_size = batch_size)\n",
    "    val_loader = data.DataLoader(val_data, shuffle=True, batch_size = batch_size)\n",
    "\n",
    "    CNNtest1 = CNN1()\n",
    "    CNNtest1.to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # Criterion for the model\n",
    "    optimizer = optim.Adam(CNNtest1.parameters(), lr) # Initialize the optimizer\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)# Initialize the scheduler\n",
    "    \n",
    "    key = lr\n",
    "    results[key] = np.zeros(epochs)\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = CNNtest1(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        running_loss = 0.0\n",
    "        scheduler.step()\n",
    "        test_acc = check_accuracy(CNNtest1, val_loader, 'forward')\n",
    "        \n",
    "        results[key][epoch] = test_acc\n",
    "    return CNNtest1, results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ded432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "results = {}\n",
    "epochs = 30\n",
    "CNNmodel, results = training(epochs, 128, results, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef20859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model accuarcy\n",
    "ep = [i for i in range(1,epochs+1)]\n",
    "for key, val in results.items():\n",
    "    plt.plot(ep, val, label=f\"Learning Rate {key}: {val[-1]:.2f}\")\n",
    "plt.legend(fontsize=10, title_fontsize=15)\n",
    "plt.title(\"full data (accuracy)\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a403a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(CNNmodel, r'./CNN2waug.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d845fcf665a7ef355472b2343010a2137a80711f9f0e1e55bd05e08e14da937"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
